{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65c952b1-ec0b-4780-b83e-b451901e0bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cf8e666-ab3d-401e-a708-7850d6614abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/phamb/pl2map')\n",
    "from runners.evaluator import Evaluator\n",
    "import util.config as utilcfg\n",
    "from omegaconf import OmegaConf\n",
    "from evaluator import Evaluator\n",
    "from util.logger import DualLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32aea92f-2fed-4301-ac33-da034a4c8b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/phamb/pl2map'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import sys, os\n",
    "\n",
    "os.getcwd() \n",
    "os.chdir(\"..\")\n",
    "sys.path.append('/home/username/pl2map')\n",
    "# replace username with appropriate name\n",
    "os.chdir('/home/username/pl2map')\n",
    "# replace username with appropriate name\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ad2a1a3-c31a-4757-b3f1-e80dcb9def8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [48:47<00:00,  1.46s/it]\n"
     ]
    }
   ],
   "source": [
    "# this code is originally from eval.py, but it needs some adjustment to run on jupyter. See above\n",
    "def parse_config():\n",
    "    arg_parser = argparse.ArgumentParser(description='pre-processing for PL2Map dataset')\n",
    "    arg_parser.add_argument('-d', '--dataset_dir', type=Path, default='train_test_datasets/imgs_datasets/', help='')\n",
    "    arg_parser.add_argument('--sfm_dir', type=Path, default='train_test_datasets/gt_3Dmodels/', help='sfm ground truth directory')\n",
    "    arg_parser.add_argument('--dataset', type=str, default=\"7scenes\", help='dataset name')\n",
    "    arg_parser.add_argument('-s', '--scene', type=str, default=\"pumpkin\", help='scene name(s)')\n",
    "    arg_parser.add_argument('-c','--cudaid', type=int, default=0, help='specify cuda device id')\n",
    "    arg_parser.add_argument('-o','--outputs', type=Path, default='logs/',\n",
    "                        help='Path to the output directory, default: %(default)s')\n",
    "    arg_parser.add_argument('-expv', '--experiment_version', type=str, default=\"pl2map\", help='experiment version folder')\n",
    "    args, _ = arg_parser.parse_known_args()\n",
    "    args.outputs = os.path.join(args.outputs, args.scene + \"_\" + args.experiment_version)\n",
    "    path_to_eval_cfg = f'{args.outputs}/config.yaml'\n",
    "    cfg = utilcfg.load_config(path_to_eval_cfg, default_path='cfgs/default.yaml')\n",
    "    cfg = OmegaConf.create(cfg)\n",
    "    return args, cfg\n",
    "\n",
    "def main():\n",
    "    eval_cfg = {\n",
    "        \"eval_train\": False, # evaluate train_loader\n",
    "        \"eval_test\": True, # evaluate test_loader\n",
    "        \"vis_point3d\": False, # visualize predicted 3D points, if eval_train/test = True\n",
    "        \"vis_line3d\": True, # visualize predicted 3D lines, if eval_train/test = True\n",
    "        \"pnp_point\": True, # use point-mode-only for PnP\n",
    "        \"pnp_pointline\": True, # use point+line mode for PnP\n",
    "        \"uncer_threshold_point\": 0.5, # threshold to remove uncertain points\n",
    "        \"uncer_threshold_line\": 0.02, # threshold to remove uncertain lines\n",
    "        \"exist_results\":False, # if True, skip running model,then use the existing results in the outputs folder\n",
    "        \"save_3dmap\": True, # save predicted 3D map\n",
    "    }\n",
    "    args, cfg = parse_config()\n",
    "    sys.stdout = DualLogger(f'{args.outputs}/eval_log.txt')\n",
    "    evaler = Evaluator(args, cfg, eval_cfg)\n",
    "    evaler.eval()\n",
    "    sys.stdout.log.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_test2",
   "language": "python",
   "name": "venv_test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
